mixformer：在原始mixformer的基础上，右侧分支：dpcov+dprnn+attention，左侧分支dprnn+attention

DPCMN_mixformer_noattention_depthwisefirst:在mixformer的基础上，去掉了右侧分支的attention 块---最好
DPCMN_mixformer_noattention：在mixformer的基础上，去掉了attention块，且先做dprnn在做dpconv
DPCMN_mixformer_nodprnn:在mixformer的基础上，右侧分支不使用dprnn结构

DPCMN_mixformer_noattention_depthwisefirst:这个是最后论文所采纳的结构

DPCRN_mixformer_noInteractions:DPCMN_mixformer_noattention_depthwisefirst的基础上没有通道交互，这个是最后写在论文里的消融实验
DPCMN_mixformer_noattention_depthwisefirst_noParallel:, 再DPCRN_mixformer_noInteractions的基础上，变成序列结构,这个结果是所有里面最好的，但是没有写进论文里